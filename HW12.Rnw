\documentclass{article}
\usepackage[margin=1.0in]{geometry} % To set margins
\usepackage{amsmath}  % This allows me to use the align functionality.
                      % If you find yourself trying to replicate
                      % something you found online, ensure you're
                      % loading the necessary packages!
\usepackage{amsfonts} % Math font
\usepackage{fancyvrb}
\usepackage{hyperref} % For including hyperlinks
\usepackage[shortlabels]{enumitem}% For enumerated lists with labels specified
                                  % We had to run tlmgr_install("enumitem") in R
\usepackage{float}    % For telling R where to put a table/figure
\usepackage{natbib}        %For the bibliography
\bibliographystyle{apalike}%For the bibliography

\begin{document}
<<echo=F, message=F, warning=F>>=
library(tidyverse)
library(VGAM)
@

\begin{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Question 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\item A group of researchers is running an experiment over the course of 30 months, 
with a single observation collected at the end of each month. Let $X_1, ..., X_{30}$
denote the observations for each month. From prior studies, the researchers know that
\[X_i \sim f_X(x),\]
but the mean $\mu_X$ is unknown, and they wish to conduct the following test
\begin{align*}
H_0&: \mu_X = 0\\
H_a&: \mu_X > 0.
\end{align*}
At month $k$, they have accumulated data $X_1, ..., X_k$ and they have the 
$t$-statistic
\[T_k = \frac{\bar{X} - 0}{S_k/\sqrt{n}}.\]
The initial plan was to test the hypotheses after all data was collected (at the 
end of month 30), at level $\alpha=0.05$. However, conducting the experiment is 
expensive, so the researchers want to ``peek" at the data at the end of month 20 
to see if they can stop it early. That is, the researchers propose to check 
whether $t_{20}$ provides statistically discernible support for the alternative. 
If it does, they will stop the experiment early and report support for the 
researcher's alternative hypothesis. If it does not, they will continue to month 
30 and test whether $t_{30}$ provides statistically discernible support for the
alternative.

\begin{enumerate}
  \item What values of $t_{20}$ provide statistically discernible support for the
  alternative hypothesis?
  <<size = 'scriptsize', message=F, warning=F>>=
mu0 <- 0
alpha <- 0.05
df_20 <- 20 -1
#get the critical value for statistically discernible support
critical_20 <- qt(p = 1 - alpha, df = df_20) 
critical_20
@
The value $t_{20}$ = \Sexpr{round(critical_20,3)} provides statisticaly discernible support for the alterative hypothesis.
  \item What values of $t_{30}$ provide statistically discernible support for the
  alternative hypothesis?
   <<size = 'scriptsize', message=F, warning=F>>=
df_30 <- 30 -1
#get the critical value for statistically discernible support
critical_30 <- qt(p = 1 - alpha, df = df_30) 
critical_30
@
The value $t_{30}$ = \Sexpr{round(critical_30,3)} provides statisticaly discernible support for the alterative hypothesis.
  \item Suppose $f_X(x)$ is a Laplace distribution with $a=0$ and $b=4.0$.
  Conduct a simulation study to assess the Type I error rate of this approach.\\
  \textbf{Note:} You can use the \texttt{rlaplace()} function from the \texttt{VGAM}
  package for \texttt{R} \citep{VGAM}.
  <<size = 'scriptsize', message=F, warning=F>>=
#Conduct a simulation study to assess the Type I error 
a <- 0
b <- 4.0
n.simulations <- 1000
type1.count <- 0 #count the number of times we got Type I error

#conduct the simulation
for (i in 1:n.simulations){
  sim <- rlaplace(n = 30, location = a, scale = b)
  #calculate the critical point
  t_sim <- mean(sim)/ (sd(sim)/sqrt(30))
  
  #check if t is larger than the critical point
  if (t_sim > critical_30){
    type1.count = type1.count + 1
  }
}

#calculate the rate of receiving Type I error 
rate.type1 <- type1.count/n.simulations
rate.type1
@
The Type I error rate for a Laplace distribution with $a=0$ and $b=4.0$ by using a simulation is \Sexpr{rate.type1} = \Sexpr{rate.type1*100}\%. 
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Question 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item Perform a simulation study to assess the robustness of the $T$ test. 
  Specifically, generate samples of size $n=15$ from the Beta(10,2), Beta(2,10), 
  and Beta(10,10) distributions and conduct the following hypothesis tests against 
  the actual mean for each case (e.g., $\frac{10}{10+2}$, $\frac{2}{10+2}$, and 
  $\frac{10}{10+10}$). 
  \begin{enumerate}
    \item What proportion of the time do we make an error of Type I for a
    left-tailed test?
    <<size = 'scriptsize', message=F, warning=F>>=
n <-15
#calculate the true means for each of beta distributions
mean.beta.10.2 <- 10/(10+2)
mean.beta.2.10 <- 2/(2+10)
mean.beta.10.10 <- 10/(10+10)

#left-tailed test for beta(10,2)
count.error.left.10.2 <- 0
#perform the simulation
for (i in 1:n.simulations){
  #get a sample from beta distribution
  sample <- rbeta(n, shape1 = 10, shape2 = 2)
  #perform a t-test on the sample
  t_test <- t.test(sample, alternative = "less", mu = mean.beta.10.2)
  #check if we got a type 1 error
  if (t_test$p.value < alpha){
    count.error.left.10.2 <- count.error.left.10.2 +1
  }
}
#calculate the proportion of time we make a Type 1 error
rate.left.10.2 <- count.error.left.10.2/n.simulations


#left-tailed test for beta(2,10)
count.error.left.2.10 <- 0
#perform the simulation
for (i in 1:n.simulations){
  #get a sample from beta distribution
  sample <- rbeta(n, shape1 = 2, shape2 = 10)
  #perform a t-test on the sample
  t_test <- t.test(sample, alternative = "less", mu = mean.beta.2.10)
  #check if we got a type 1 error
  if (t_test$p.value < alpha){
    count.error.left.2.10 <- count.error.left.2.10 +1
  }
}
#calculate the proportion of time we make a Type 1 error
rate.left.2.10 <- count.error.left.2.10/n.simulations


#left-tailed test for beta(10,10)
count.error.left.10.10 <- 0
#perform the simulation
for (i in 1:n.simulations){
  #get a sample from beta distribution
  sample <- rbeta(n, shape1 = 10, shape2 = 10)
  #perform a t-test on the sample
  t_test <- t.test(sample, alternative = "less", mu = mean.beta.10.10)
  #check if we got a type 1 error
  if (t_test$p.value < alpha){
    count.error.left.10.10 <- count.error.left.10.10 +1
  }
}
#calculate the proportion of time we make a Type 1 error
rate.left.10.10 <- count.error.left.10.10/n.simulations

rate.left.10.2
rate.left.2.10
rate.left.10.10
@
We make an error of Type I for a left-tailed test \Sexpr{rate.left.10.2} = \Sexpr{rate.left.10.2*100}\% for Beta(10,2),  \Sexpr{rate.left.2.10} = \Sexpr{rate.left.2.10*100}\% for Beta(2,10), and \Sexpr{rate.left.10.10} = \Sexpr{rate.left.10.10*100}\% for Beta(10,10).
    \item What proportion of the time do we make an error of Type I for a
    right-tailed test?
    <<size = 'scriptsize', message=F, warning=F>>=
#right-tailed test for beta(10,2)
count.error.right.10.2 <- 0
#perform the simulation
for (i in 1:n.simulations){
  #get a sample from beta distribution
  sample <- rbeta(n, shape1 = 10, shape2 = 2)
  #perform a t-test on the sample
  t_test <- t.test(sample, alternative = "greater", mu = mean.beta.10.2)
  #check if we got a type 1 error
  if (t_test$p.value < alpha){
    count.error.right.10.2 <- count.error.right.10.2 +1
  }
}
#calculate the proportion of time we make a Type 1 error
rate.right.10.2 <- count.error.right.10.2/n.simulations


#right-tailed test for beta(2,10)
count.error.right.2.10 <- 0
#perform the simulation
for (i in 1:n.simulations){
  #get a sample from beta distribution
  sample <- rbeta(n, shape1 = 2, shape2 = 10)
  #perform a t-test on the sample
  t_test <- t.test(sample, alternative = "greater", mu = mean.beta.2.10)
  #check if we got a type 1 error
  if (t_test$p.value < alpha){
    count.error.right.2.10 <- count.error.right.2.10 +1
  }
}
#calculate the proportion of time we make a Type 1 error
rate.right.2.10 <- count.error.right.2.10/n.simulations


#right-tailed test for beta(10,10)
count.error.right.10.10 <- 0
#perform the simulation
for (i in 1:n.simulations){
  #get a sample from beta distribution
  sample <- rbeta(n, shape1 = 10, shape2 = 10)
  #perform a t-test on the sample
  t_test <- t.test(sample, alternative = "greater", mu = mean.beta.10.10)
  #check if we got a type 1 error
  if (t_test$p.value < alpha){
    count.error.right.10.10 <- count.error.right.10.10 +1
  }
}
#calculate the proportion of time we make a Type 1 error
rate.right.10.10 <- count.error.right.10.10/n.simulations

rate.right.10.2
rate.right.2.10
rate.right.10.10
@
We make an error of Type I for a right-tailed test \Sexpr{rate.right.10.2} = \Sexpr{rate.right.10.2*100}\% for Beta(10,2),  \Sexpr{rate.right.2.10} = \Sexpr{rate.right.2.10*100}\% for Beta(2,10), and \Sexpr{rate.right.10.10} = \Sexpr{rate.right.10.10*100}\% for Beta(10,10).
    \item What proportion of the time do we make an error of Type I for a
    two-tailed test?
    <<size = 'scriptsize', message=F, warning=F>>=
#two-tailed test for beta(10,2)
count.error.two.10.2 <- 0
#perform the simulation
for (i in 1:n.simulations){
  #get a sample from beta distribution
  sample <- rbeta(n, shape1 = 10, shape2 = 2)
  #perform a t-test on the sample
  t_test <- t.test(sample, alternative = "two.sided", mu = mean.beta.10.2)
  #check if we got a type 1 error
  if (t_test$p.value < alpha){
    count.error.two.10.2 <- count.error.two.10.2 +1
  }
}
#calculate the proportion of time we make a Type 1 error
rate.two.10.2 <- count.error.two.10.2/n.simulations


#two-tailed test for beta(2,10)
count.error.two.2.10 <- 0
#perform the simulation
for (i in 1:n.simulations){
  #get a sample from beta distribution
  sample <- rbeta(n, shape1 = 2, shape2 = 10)
  #perform a t-test on the sample
  t_test <- t.test(sample, alternative = "two.sided", mu = mean.beta.2.10)
  #check if we got a type 1 error
  if (t_test$p.value < alpha){
    count.error.two.2.10 <- count.error.two.2.10 +1
  }
}
#calculate the proportion of time we make a Type 1 error
rate.two.2.10 <- count.error.two.2.10/n.simulations


#two-tailed test for beta(10,10)
count.error.two.10.10 <- 0
#perform the simulation
for (i in 1:n.simulations){
  #get a sample from beta distribution
  sample <- rbeta(n, shape1 = 10, shape2 = 10)
  #perform a t-test on the sample
  t_test <- t.test(sample, alternative = "two.sided", mu = mean.beta.10.10)
  #check if we got a type 1 error
  if (t_test$p.value < alpha){
    count.error.two.10.10 <- count.error.two.10.10 +1
  }
}
#calculate the proportion of time we make a Type 1 error
rate.two.10.10 <- count.error.two.10.10/n.simulations

rate.two.10.2
rate.two.2.10
rate.two.10.10
@
We make an error of Type I for a two-tailed test \Sexpr{rate.two.10.2} = \Sexpr{rate.two.10.2*100}\% for Beta(10,2),  \Sexpr{rate.two.2.10} = \Sexpr{rate.two.2.10*100}\% for Beta(2,10), and \Sexpr{rate.two.10.10} = \Sexpr{rate.two.10.10*100}\% for Beta(10,10).
    \item How does skewness of the underlying population distribution effect
    Type I error across the test types? \\
    For a right-skewed distribution, Beta(2,10), the Type I error is inflated for the right-tailed test. For a left-skewed distribution, Beta(10,2), the Type I error is inflated for the left-tailed test. For a symmetrical distribution, Beta(10,10), the Type I error is approximately 0.05 for all test types.
    Overall, for the left-tailed test, the right-skewed distribution has the smallest Type I error. For the right-tailed test, the left-skewed distribution has the smallest Type I error. For the two-tailed test, the symmetrical distribution has the smallest Type I error.  
  \end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% End Document
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{enumerate}
\bibliography{bibliography}
\end{document}
